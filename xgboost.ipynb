{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 天池大赛·印象盐城\n",
    "\n",
    "## 测试数据\n",
    "\n",
    "初赛提供2012年1月-2017年10月盐城分车型销量配置数据。\n",
    "第一阶段需要参赛者预测2017年11月盐城分车型销量数据，第二阶段需要参赛者预测2017年12月盐城分车型销量数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import *\n",
    "import random\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('trainSaleDate.csv')\n",
    "test = pd.read_csv('test_feature.csv')\n",
    "submit = pd.read_csv('../yancheng_testA_20171225.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = train.sale_quantity\n",
    "train = train.drop(['class_id','sale_quantity'], axis=1)\n",
    "\n",
    "train_test = pd.concat([train, test]).reset_index(drop=True)\n",
    "year_dummies = pd.get_dummies(train_test['year'], prefix='year')\n",
    "mouth_dummies = pd.get_dummies(train_test['mouth'], prefix='mouth')\n",
    "train_test = pd.concat([train_test, year_dummies, mouth_dummies], axis=1)\n",
    "# train_test.drop(['year', 'mouth'], axis=1)\n",
    "train_test.fillna(0.0, inplace=True)\n",
    "\n",
    "train = train_test[0:9800].reset_index(drop=True)\n",
    "test = train_test[9800:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9800, 177)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140, 177)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reg = XGBRegressor()\n",
    "# for i in range(5):\n",
    "    \n",
    "#     train_X,test_X, train_y, test_y = train_test_split(train,  \n",
    "#                                                         labels,  \n",
    "#                                                         test_size = 0.2)\n",
    "#     reg.fit(train_X, train_y)\n",
    "#     y_pred = reg.predict(test_X)\n",
    "\n",
    "#     rmsetmp = sp.sqrt(sp.mean((test_y - y_pred) ** 2))\n",
    "#     print(rmsetmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# trainset = xgb.DMatrix(train,label=labels)\n",
    "# testset = xgb.DMatrix(test)\n",
    "\n",
    "# params = {\n",
    "#     'booster': 'gbtree',\n",
    "#     'objective': 'reg:linear',\n",
    "#     'eval_metric': 'rmse',\n",
    "#     'gamma': 0.1,\n",
    "#     'min_child_weight': 1.2,\n",
    "#     'max_depth': 6,\n",
    "#     'lambda': 10,\n",
    "#     'subsample': 0.95,\n",
    "#     'colsample_bytree': 0.78,\n",
    "#     'tree_method': 'exact'\n",
    "# }\n",
    "\n",
    "# watchlist = [(trainset,'train')]\n",
    "# model = xgb.train(params,trainset,num_boost_round=20,evals=watchlist)\n",
    "\n",
    "# submit['predict_quantity'] = model.predict(testset)\n",
    "# submit.to_csv(\"xgb_preds.csv\", index=None)\n",
    "# print(submit.describe())\n",
    "\n",
    "# feature_score = model.get_fscore()\n",
    "# feature_score = sorted(feature_score.items(), key=lambda x:x[1],reverse=True)\n",
    "# fs = []\n",
    "# for (key,value) in feature_score:\n",
    "#     fs.append(\"{0},{1}\\n\".format(key,value))\n",
    "    \n",
    "# with open('xgb_feature_score.csv','w') as f:\n",
    "#     f.writelines(\"feature,score\\n\")\n",
    "#     f.writelines(fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:398.788\ttest-rmse:487.626\n",
      "[1]\ttrain-rmse:311.611\ttest-rmse:392.865\n",
      "[2]\ttrain-rmse:251.782\ttest-rmse:333.276\n",
      "[3]\ttrain-rmse:212.934\ttest-rmse:299.959\n",
      "[4]\ttrain-rmse:183.909\ttest-rmse:280.492\n",
      "[5]\ttrain-rmse:163.535\ttest-rmse:269.315\n",
      "[6]\ttrain-rmse:146.821\ttest-rmse:263.942\n",
      "[7]\ttrain-rmse:133.228\ttest-rmse:265.389\n",
      "[8]\ttrain-rmse:122.446\ttest-rmse:264.851\n",
      "[9]\ttrain-rmse:113.593\ttest-rmse:267.552\n",
      "[10]\ttrain-rmse:106.143\ttest-rmse:269.061\n",
      "[11]\ttrain-rmse:99.3097\ttest-rmse:269.426\n",
      "[12]\ttrain-rmse:94.0394\ttest-rmse:269.025\n",
      "[13]\ttrain-rmse:89.1386\ttest-rmse:268.78\n",
      "[14]\ttrain-rmse:84.828\ttest-rmse:269.371\n",
      "[15]\ttrain-rmse:80.9683\ttest-rmse:270.182\n",
      "[16]\ttrain-rmse:77.9763\ttest-rmse:270.645\n",
      "[17]\ttrain-rmse:75.4852\ttest-rmse:271.496\n",
      "[18]\ttrain-rmse:72.4164\ttest-rmse:272.479\n",
      "[19]\ttrain-rmse:69.6562\ttest-rmse:272.973\n",
      "[20]\ttrain-rmse:67.9132\ttest-rmse:273.276\n",
      "[21]\ttrain-rmse:65.9243\ttest-rmse:273.656\n",
      "[22]\ttrain-rmse:64.0403\ttest-rmse:273.455\n",
      "[23]\ttrain-rmse:62.1956\ttest-rmse:273.86\n",
      "[24]\ttrain-rmse:60.5225\ttest-rmse:274.542\n",
      "[25]\ttrain-rmse:58.9948\ttest-rmse:274.285\n",
      "[26]\ttrain-rmse:57.2041\ttest-rmse:275.132\n",
      "[27]\ttrain-rmse:55.4673\ttest-rmse:275.899\n",
      "[28]\ttrain-rmse:53.9854\ttest-rmse:277.302\n",
      "[29]\ttrain-rmse:52.6989\ttest-rmse:277.722\n",
      "[30]\ttrain-rmse:51.4063\ttest-rmse:278.352\n",
      "[31]\ttrain-rmse:49.3484\ttest-rmse:277.173\n",
      "[32]\ttrain-rmse:47.7836\ttest-rmse:276.671\n",
      "[33]\ttrain-rmse:47.0804\ttest-rmse:276.844\n",
      "[34]\ttrain-rmse:46.6072\ttest-rmse:276.979\n",
      "[35]\ttrain-rmse:45.6181\ttest-rmse:276.816\n",
      "[36]\ttrain-rmse:44.9682\ttest-rmse:276.916\n",
      "[37]\ttrain-rmse:44.3842\ttest-rmse:277.171\n",
      "[38]\ttrain-rmse:43.8086\ttest-rmse:277.327\n",
      "[39]\ttrain-rmse:43.1671\ttest-rmse:277.197\n",
      "[40]\ttrain-rmse:41.9229\ttest-rmse:277.307\n",
      "[41]\ttrain-rmse:41.5003\ttest-rmse:277.443\n",
      "[42]\ttrain-rmse:41.0733\ttest-rmse:277.73\n",
      "[43]\ttrain-rmse:40.8565\ttest-rmse:277.724\n",
      "[44]\ttrain-rmse:39.8801\ttest-rmse:278.009\n",
      "[45]\ttrain-rmse:39.1403\ttest-rmse:278.162\n",
      "[46]\ttrain-rmse:38.3802\ttest-rmse:278.397\n",
      "[47]\ttrain-rmse:38.0636\ttest-rmse:278.544\n",
      "[48]\ttrain-rmse:37.0378\ttest-rmse:278.597\n",
      "[49]\ttrain-rmse:36.5015\ttest-rmse:278.947\n",
      "[50]\ttrain-rmse:35.5321\ttest-rmse:279.167\n",
      "[51]\ttrain-rmse:35.3017\ttest-rmse:279.212\n",
      "[52]\ttrain-rmse:34.7744\ttest-rmse:279.916\n",
      "[53]\ttrain-rmse:34.5789\ttest-rmse:279.906\n",
      "[54]\ttrain-rmse:34.1096\ttest-rmse:279.886\n",
      "[55]\ttrain-rmse:33.6386\ttest-rmse:280.052\n",
      "[56]\ttrain-rmse:33.0543\ttest-rmse:280.269\n",
      "[57]\ttrain-rmse:32.9576\ttest-rmse:280.366\n",
      "[58]\ttrain-rmse:32.688\ttest-rmse:280.382\n",
      "[59]\ttrain-rmse:32.2929\ttest-rmse:280.357\n",
      "[60]\ttrain-rmse:32.1665\ttest-rmse:280.32\n",
      "[61]\ttrain-rmse:31.2295\ttest-rmse:280.321\n",
      "[62]\ttrain-rmse:30.675\ttest-rmse:280.363\n",
      "[63]\ttrain-rmse:29.8443\ttest-rmse:280.309\n",
      "[64]\ttrain-rmse:29.3982\ttest-rmse:280.208\n",
      "[65]\ttrain-rmse:29.0487\ttest-rmse:280.239\n",
      "[66]\ttrain-rmse:28.8705\ttest-rmse:280.175\n",
      "[67]\ttrain-rmse:28.7536\ttest-rmse:280.217\n",
      "[68]\ttrain-rmse:28.6646\ttest-rmse:280.314\n",
      "[69]\ttrain-rmse:28.3055\ttest-rmse:280.414\n",
      "[70]\ttrain-rmse:28.0115\ttest-rmse:280.367\n",
      "[71]\ttrain-rmse:27.7389\ttest-rmse:280.34\n",
      "[72]\ttrain-rmse:27.5298\ttest-rmse:280.402\n",
      "[73]\ttrain-rmse:26.9228\ttest-rmse:280.387\n",
      "[74]\ttrain-rmse:26.5599\ttest-rmse:280.502\n",
      "[75]\ttrain-rmse:26.2352\ttest-rmse:280.387\n",
      "[76]\ttrain-rmse:26.1748\ttest-rmse:280.473\n",
      "[77]\ttrain-rmse:25.8891\ttest-rmse:280.57\n",
      "[78]\ttrain-rmse:25.5783\ttest-rmse:280.598\n",
      "[79]\ttrain-rmse:25.1759\ttest-rmse:280.8\n",
      "[80]\ttrain-rmse:24.7544\ttest-rmse:280.884\n",
      "[81]\ttrain-rmse:24.4008\ttest-rmse:281.024\n",
      "[82]\ttrain-rmse:23.9435\ttest-rmse:280.938\n",
      "[83]\ttrain-rmse:23.6927\ttest-rmse:280.95\n",
      "[84]\ttrain-rmse:23.3123\ttest-rmse:280.959\n",
      "[85]\ttrain-rmse:23.1157\ttest-rmse:281.108\n",
      "[86]\ttrain-rmse:22.7549\ttest-rmse:281.086\n",
      "[87]\ttrain-rmse:22.5777\ttest-rmse:281.169\n",
      "[88]\ttrain-rmse:22.1672\ttest-rmse:281.205\n",
      "[89]\ttrain-rmse:21.8821\ttest-rmse:281.045\n",
      "[90]\ttrain-rmse:21.5091\ttest-rmse:281.05\n",
      "[91]\ttrain-rmse:21.4083\ttest-rmse:281.139\n",
      "[92]\ttrain-rmse:21.2165\ttest-rmse:281.133\n",
      "[93]\ttrain-rmse:20.8197\ttest-rmse:281.143\n",
      "[94]\ttrain-rmse:20.6088\ttest-rmse:281.2\n",
      "[95]\ttrain-rmse:20.2987\ttest-rmse:281.221\n",
      "[96]\ttrain-rmse:20.1995\ttest-rmse:281.328\n",
      "[97]\ttrain-rmse:19.9959\ttest-rmse:281.288\n",
      "[98]\ttrain-rmse:19.8778\ttest-rmse:281.276\n",
      "[99]\ttrain-rmse:19.53\ttest-rmse:281.259\n",
      "[100]\ttrain-rmse:19.3938\ttest-rmse:281.166\n",
      "[101]\ttrain-rmse:19.0061\ttest-rmse:281.123\n",
      "[102]\ttrain-rmse:18.7211\ttest-rmse:281.111\n",
      "[103]\ttrain-rmse:18.4737\ttest-rmse:281.118\n",
      "[104]\ttrain-rmse:18.206\ttest-rmse:281.088\n",
      "[105]\ttrain-rmse:18.1738\ttest-rmse:281.116\n",
      "[106]\ttrain-rmse:18.0342\ttest-rmse:281.116\n",
      "[107]\ttrain-rmse:17.8672\ttest-rmse:281.034\n",
      "[108]\ttrain-rmse:17.6283\ttest-rmse:281.219\n",
      "[109]\ttrain-rmse:17.4328\ttest-rmse:281.242\n",
      "[110]\ttrain-rmse:17.2618\ttest-rmse:281.191\n",
      "[111]\ttrain-rmse:16.9958\ttest-rmse:281.221\n",
      "[112]\ttrain-rmse:16.966\ttest-rmse:281.241\n",
      "[113]\ttrain-rmse:16.7232\ttest-rmse:281.218\n",
      "[114]\ttrain-rmse:16.6732\ttest-rmse:281.244\n",
      "[115]\ttrain-rmse:16.5941\ttest-rmse:281.315\n",
      "[116]\ttrain-rmse:16.296\ttest-rmse:281.33\n",
      "[117]\ttrain-rmse:16.0265\ttest-rmse:281.408\n",
      "[118]\ttrain-rmse:15.7175\ttest-rmse:281.436\n",
      "[119]\ttrain-rmse:15.473\ttest-rmse:281.448\n",
      "[120]\ttrain-rmse:15.2517\ttest-rmse:281.503\n",
      "[121]\ttrain-rmse:15.0945\ttest-rmse:281.586\n",
      "[122]\ttrain-rmse:14.9093\ttest-rmse:281.594\n",
      "[123]\ttrain-rmse:14.7906\ttest-rmse:281.602\n",
      "[124]\ttrain-rmse:14.5712\ttest-rmse:281.631\n",
      "[125]\ttrain-rmse:14.5075\ttest-rmse:281.762\n",
      "[126]\ttrain-rmse:14.4011\ttest-rmse:281.742\n",
      "[127]\ttrain-rmse:14.1888\ttest-rmse:281.781\n",
      "[128]\ttrain-rmse:14.1009\ttest-rmse:281.816\n",
      "[129]\ttrain-rmse:14.0222\ttest-rmse:281.858\n",
      "[130]\ttrain-rmse:13.7744\ttest-rmse:281.859\n",
      "[131]\ttrain-rmse:13.6913\ttest-rmse:281.847\n",
      "[132]\ttrain-rmse:13.5878\ttest-rmse:281.827\n",
      "[133]\ttrain-rmse:13.4421\ttest-rmse:281.808\n",
      "[134]\ttrain-rmse:13.3646\ttest-rmse:281.825\n",
      "[135]\ttrain-rmse:13.2824\ttest-rmse:281.854\n",
      "[136]\ttrain-rmse:13.0892\ttest-rmse:281.852\n",
      "[137]\ttrain-rmse:12.9533\ttest-rmse:281.907\n",
      "[138]\ttrain-rmse:12.9355\ttest-rmse:281.91\n",
      "[139]\ttrain-rmse:12.6792\ttest-rmse:281.896\n",
      "[140]\ttrain-rmse:12.5752\ttest-rmse:281.902\n",
      "[141]\ttrain-rmse:12.4001\ttest-rmse:281.921\n",
      "[142]\ttrain-rmse:12.2807\ttest-rmse:281.902\n",
      "[143]\ttrain-rmse:12.245\ttest-rmse:281.877\n",
      "[144]\ttrain-rmse:11.9845\ttest-rmse:281.899\n",
      "[145]\ttrain-rmse:11.9102\ttest-rmse:281.942\n",
      "[146]\ttrain-rmse:11.6795\ttest-rmse:282.025\n",
      "[147]\ttrain-rmse:11.5839\ttest-rmse:282.12\n",
      "[148]\ttrain-rmse:11.51\ttest-rmse:282.148\n",
      "[149]\ttrain-rmse:11.3765\ttest-rmse:282.189\n",
      "[150]\ttrain-rmse:11.2824\ttest-rmse:282.183\n",
      "[151]\ttrain-rmse:11.1402\ttest-rmse:282.252\n",
      "[152]\ttrain-rmse:11.0921\ttest-rmse:282.326\n",
      "[153]\ttrain-rmse:11.0062\ttest-rmse:282.342\n",
      "[154]\ttrain-rmse:10.8571\ttest-rmse:282.359\n",
      "[155]\ttrain-rmse:10.7869\ttest-rmse:282.367\n",
      "[156]\ttrain-rmse:10.6865\ttest-rmse:282.38\n",
      "[157]\ttrain-rmse:10.5664\ttest-rmse:282.383\n",
      "[158]\ttrain-rmse:10.5279\ttest-rmse:282.386\n",
      "[159]\ttrain-rmse:10.3873\ttest-rmse:282.358\n",
      "[160]\ttrain-rmse:10.2644\ttest-rmse:282.385\n",
      "[161]\ttrain-rmse:10.1238\ttest-rmse:282.401\n",
      "[162]\ttrain-rmse:9.9737\ttest-rmse:282.438\n",
      "[163]\ttrain-rmse:9.82301\ttest-rmse:282.473\n",
      "[164]\ttrain-rmse:9.64443\ttest-rmse:282.493\n",
      "[165]\ttrain-rmse:9.60382\ttest-rmse:282.486\n",
      "[166]\ttrain-rmse:9.47646\ttest-rmse:282.47\n",
      "[167]\ttrain-rmse:9.35448\ttest-rmse:282.487\n",
      "[168]\ttrain-rmse:9.22249\ttest-rmse:282.507\n",
      "[169]\ttrain-rmse:9.06566\ttest-rmse:282.51\n",
      "[170]\ttrain-rmse:9.04573\ttest-rmse:282.503\n",
      "[171]\ttrain-rmse:8.96391\ttest-rmse:282.544\n",
      "[172]\ttrain-rmse:8.88312\ttest-rmse:282.555\n",
      "[173]\ttrain-rmse:8.71206\ttest-rmse:282.562\n",
      "[174]\ttrain-rmse:8.64375\ttest-rmse:282.535\n",
      "[175]\ttrain-rmse:8.52541\ttest-rmse:282.536\n",
      "[176]\ttrain-rmse:8.47054\ttest-rmse:282.524\n",
      "[177]\ttrain-rmse:8.29404\ttest-rmse:282.522\n",
      "[178]\ttrain-rmse:8.07422\ttest-rmse:282.538\n",
      "[179]\ttrain-rmse:7.95927\ttest-rmse:282.568\n",
      "[180]\ttrain-rmse:7.88711\ttest-rmse:282.589\n",
      "[181]\ttrain-rmse:7.76469\ttest-rmse:282.589\n",
      "[182]\ttrain-rmse:7.66562\ttest-rmse:282.597\n",
      "[183]\ttrain-rmse:7.53433\ttest-rmse:282.561\n",
      "[184]\ttrain-rmse:7.49827\ttest-rmse:282.571\n",
      "[185]\ttrain-rmse:7.44142\ttest-rmse:282.578\n",
      "[186]\ttrain-rmse:7.3504\ttest-rmse:282.574\n",
      "[187]\ttrain-rmse:7.28176\ttest-rmse:282.604\n",
      "[188]\ttrain-rmse:7.20962\ttest-rmse:282.651\n",
      "[189]\ttrain-rmse:7.07049\ttest-rmse:282.619\n",
      "[190]\ttrain-rmse:6.99656\ttest-rmse:282.591\n",
      "[191]\ttrain-rmse:6.97573\ttest-rmse:282.62\n",
      "[192]\ttrain-rmse:6.91287\ttest-rmse:282.614\n",
      "[193]\ttrain-rmse:6.77778\ttest-rmse:282.652\n",
      "[194]\ttrain-rmse:6.71711\ttest-rmse:282.657\n",
      "[195]\ttrain-rmse:6.64744\ttest-rmse:282.62\n",
      "[196]\ttrain-rmse:6.62348\ttest-rmse:282.63\n",
      "[197]\ttrain-rmse:6.55987\ttest-rmse:282.648\n",
      "[198]\ttrain-rmse:6.50872\ttest-rmse:282.625\n",
      "[199]\ttrain-rmse:6.39664\ttest-rmse:282.596\n",
      "This time rmse is: 282.595988998\n"
     ]
    }
   ],
   "source": [
    "# for i in range(1):\n",
    "    \n",
    "# #     train = train.drop([''])\n",
    "    \n",
    "# #     train_X,test_X, train_y, test_y = train_test_split(train,  \n",
    "# #                                                         labels,  \n",
    "# #                                                         test_size = 0.2)\n",
    "\n",
    "#     train_X = train[0:8260]\n",
    "#     test_X = train[8260:]\n",
    "#     train_y = labels[0:8260]\n",
    "#     test_y = labels[8260:]\n",
    "    \n",
    "# #     pca = PCA(0.95, True, True)\n",
    "# #     train_X = pca.fit_transform(train_X)\n",
    "# #     test_X = pca.transform(test_X)\n",
    "\n",
    "# #     selectKBest = SelectKBest(lambda X, Y: np.array(map(lambda x:pearsonr(x, Y), X.T)).T, k=150)\n",
    "# #     train_X = selectKBest.fit_transform(train_X, train_y)\n",
    "# #     test_X = selectKBest.transform(test_X)\n",
    "    \n",
    "#     trainset = xgb.DMatrix(train_X,label=train_y)\n",
    "#     testset = xgb.DMatrix(test_X,label=test_y)\n",
    "    \n",
    "#     params = {\n",
    "#     'booster': 'gbtree',\n",
    "#     'objective': 'reg:linear',\n",
    "#     'eval_metric': 'rmse',\n",
    "#     'gamma': 0.1,\n",
    "#     'min_child_weight': 1.2,\n",
    "#     'max_depth': 6,\n",
    "#     'lambda': 10,\n",
    "#     'subsample': 0.95,\n",
    "#     'colsample_bytree': 0.78,\n",
    "#     'tree_method': 'exact'\n",
    "#     }\n",
    "    \n",
    "#     watchlist = [(trainset,'train'),(testset,'test')]\n",
    "#     model = xgb.train(params,trainset,num_boost_round=200,evals=watchlist)\n",
    "    \n",
    "#     predict_test_X = model.predict(testset)\n",
    "\n",
    "#     rmsetmp = sp.sqrt(sp.mean((test_y - predict_test_X) ** 2))\n",
    "#     print('This time rmse is: '+str(rmsetmp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "params = {\n",
    "    'booster': 'gbtree',\n",
    "    'objective': 'reg:linear',\n",
    "    'eval_metric': 'rmse',\n",
    "    'gamma': 0.1,\n",
    "    'min_child_weight': 1.1,\n",
    "    'max_depth': 5,\n",
    "    'lambda': 10,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'tree_method': 'exact'\n",
    "    }\n",
    "\n",
    "RMSE(3500):160.93,160.96,106.86,127.46,127.37,99.64,210.12,130.34,124.91,128.37\n",
    "\n",
    "RMSE(4000):117,120,141,133,136,209.57,169.28,115.66,174.14,124.22\n",
    "\n",
    "RMSE(4500):123.19,187.95,147.28,149.68\n",
    "\n",
    "RMSE(5000):137,113,165,198,119"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "params = {\n",
    "    'booster': 'gbtree',\n",
    "    'objective': 'reg:linear',\n",
    "    'eval_metric': 'rmse',\n",
    "    'gamma': 0.1,\n",
    "    'min_child_weight': 1.1,\n",
    "    'max_depth': 6,\n",
    "    'lambda': 10,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'tree_method': 'exact'\n",
    "    }\n",
    "\n",
    "RMSE(3500):168.76,188.53,130.01,173.07,148.32\n",
    "    \n",
    "RMSE(4000):167.84,114.02，162.54，177.91，168.60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
